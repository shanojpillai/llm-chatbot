# **Day 1: LLM-Powered Customer Support Chatbot**  
ğŸš€ **A customer support chatbot powered by Mistral 7B, SQLite, and Docker**  

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)  
[![Docker](https://img.shields.io/badge/Docker-âœ”-blue.svg)](https://www.docker.com/)  
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)  

---
![image](https://github.com/user-attachments/assets/a022fa6c-e741-48c8-8651-65149a250490)


## **ğŸ“Œ Features**  
âœ… Uses **Mistral 7B** for natural language responses via **Ollama**  
âœ… Tracks **order status** using an **SQLite database**  
âœ… Runs **inside Docker** for easy deployment  
âœ… Fully **integrated with GitHub**  

---

## **ğŸ“Œ Technologies Used**  
- ğŸ§  **LLM Model**: Mistral 7B (via Ollama)  
- ğŸ“‚ **Database**: SQLite (stores order tracking data)  
- ğŸ³ **Containerization**: Docker  
- ğŸ **Language**: Python  
- ğŸŒ **Version Control**: Git & GitHub  

---

## **ğŸ“Œ Setup Instructions**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/shanojpillai/llm-chatbot.git
cd llm-chatbot
```

### **2ï¸âƒ£ Install Ollama (Locally)**
If you haven't installed **Ollama**, install it using:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```
For Windows, download from: [https://ollama.com](https://ollama.com)

### **3ï¸âƒ£ Pull Mistral 7B**
```bash
ollama pull mistral
```

---

## **ğŸ“Œ Running the Chatbot (Without Docker)**
If you want to test the chatbot **without Docker**, install dependencies:  
```bash
pip install requests
```
Then, run the chatbot:
```bash
python chatbot.py
```

---

## **ğŸ“Œ Database Setup (SQLite)**
### **1ï¸âƒ£ Create the Database**
Run this command:
```bash
python setup_db.py
```

---

## **ğŸ“Œ Using Docker for SQLite & Chatbot**
### **1ï¸âƒ£ Build the Docker Image**
```bash
docker build -t chatbot .
```

### **2ï¸âƒ£ Run Database Setup Inside Docker**
```bash
docker run --rm -v chatbot_data:/app chatbot python /app/setup_db.py
```

### **3ï¸âƒ£ Run the Chatbot Inside Docker**
```bash
docker run --network host -it chatbot
```

---

## **ğŸ“Œ Pushing the Project to GitHub**
### **1ï¸âƒ£ Initialize Git**
```bash
git init
git branch -M main
```

### **2ï¸âƒ£ Link to GitHub**
```bash
git remote add origin https://github.com/shanojpillai/llm-chatbot.git
```

### **3ï¸âƒ£ Add Files & Commit**
```bash
git add .
git commit -m "Initial commit: Add chatbot with SQLite and Docker"
```

### **4ï¸âƒ£ Push to GitHub**
```bash
git push -u origin main
```

âœ… **Now your chatbot project is on GitHub!** ğŸ‰  

---

## **ğŸ“Œ Next Steps**
Now that your chatbot is fully functional, we can:  

âœ… **Turn it into an API** using **FastAPI**  
âœ… **Build a Web UI** using **Streamlit or React**  
âœ… **Deploy the chatbot online** using **Docker Hub & GitHub Actions**  

---





---

### **ğŸ“Œ README Update: Day 2 - Adding a Web UI & Running Everything in Docker**  

---

# **ğŸš€ Day 2: Adding a Web UI & Running Everything in Docker**  

Today, we **expanded our chatbot project** by adding a **fully functional Web UI using Streamlit** and integrating it with our **FastAPI-based chatbot**. We also ensured **everything runs seamlessly inside Docker**. Below is a step-by-step breakdown of what we accomplished.

---

## **ğŸ“Œ Steps We Accomplished Today**  

### **1ï¸âƒ£ Built a Web UI for the Chatbot using Streamlit**  
- Created a new file **`web_ui.py`** to serve as the **frontend**.  
- Used **Streamlit** to create a simple UI where users can **type a question** and get a response from the chatbot.  
- Integrated an **API call to FastAPI** (`http://localhost:8000/chat`) inside the Streamlit app.  

âœ… **Outcome:** Users can now interact with the chatbot using a user-friendly web interface instead of just a terminal.  



---

### **2ï¸âƒ£ Updated the `Dockerfile` to Run Both FastAPI & Streamlit**  
- Installed **Streamlit** inside the Docker container.  
- Ensured that both **FastAPI (port 8000) and Streamlit (port 8501) run inside the same container**.  
- Used the following **CMD command** in `Dockerfile` to run both services:  

```dockerfile
CMD sh -c "uvicorn api:app --host 0.0.0.0 --port 8000 & sleep 5 && streamlit run web_ui.py --server.port 8501 --server.address 0.0.0.0"
```
âœ… **Outcome:** Now, when the Docker container starts, both FastAPI and Streamlit launch automatically.  

---

### **3ï¸âƒ£ Updated `docker-compose.yml` to Expose Both Ports**  
- Ensured **port mapping for FastAPI (`8000`) and Streamlit (`8501`)** is correctly configured.  
- Added the following lines inside `docker-compose.yml`:  

```yaml
services:
  chatbot:
    build: .
    container_name: chatbot_container
    ports:
      - "8000:8000"  # Exposing FastAPI
      - "8501:8501"  # Exposing Streamlit UI
```
âœ… **Outcome:** The chatbot API and Web UI are now accessible on **`http://localhost:8000`** and **`http://localhost:8501`**, respectively.  

---

### **4ï¸âƒ£ Fixed API Connection Issues Between FastAPI & Streamlit**  
- Initially, Streamlit couldnâ€™t connect to the chatbot API due to **Docker networking issues**.  
- Updated **`web_ui.py`** to dynamically detect the API URL inside Docker:  

```python
import os
API_URL = os.getenv("API_URL", "http://localhost:8000/chat")
```
- Passed `API_URL` inside `docker-compose.yml` to **ensure connectivity**:  

```yaml
environment:
  - API_URL=http://localhost:8000/chat
```
âœ… **Outcome:** Now, Streamlit correctly sends requests to FastAPI inside Docker.  

---

### **5ï¸âƒ£ Rebuilt and Successfully Ran Everything in Docker**  
- Stopped any running containers:  
  ```bash
  docker-compose down
  ```
- Rebuilt everything with the latest changes:  
  ```bash
  docker-compose build --no-cache
  ```
- Started the chatbot and Web UI inside Docker:  
  ```bash
  docker-compose up
  ```
âœ… **Outcome:** Everything runs inside Docker, and the chatbot is now fully functional with a web-based interface! ğŸ‰  

---

## **ğŸ“Œ Final Folder Structure**
```
llm-chatbot/
â”œâ”€â”€ Dockerfile             # Docker setup for FastAPI & Streamlit
â”œâ”€â”€ docker-compose.yml     # Runs FastAPI + Streamlit inside Docker
â”œâ”€â”€ api.py                 # FastAPI backend for chatbot API
â”œâ”€â”€ web_ui.py              # Streamlit frontend for chatbot UI
â”œâ”€â”€ setup_db.py            # Initializes SQLite database
â”œâ”€â”€ chatbot.py             # Legacy chatbot script (now inside FastAPI)
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ orders.db              # SQLite database (auto-created, not in Git)
â””â”€â”€ README.md              # Documentation
```
âœ… **Now, our chatbot has a user-friendly web interface and runs fully inside Docker!** ğŸš€  

---

## **ğŸ“Œ How to Run the Project**
### **1ï¸âƒ£ Start the Chatbot & Web UI**
```bash
docker-compose up --build
```
âœ… **FastAPI API:** **[http://localhost:8000](http://localhost:8000)**  
âœ… **Streamlit Web UI:** **[http://localhost:8501](http://localhost:8501)**  

### **2ï¸âƒ£ Using the Chatbot**
1ï¸âƒ£ Open **[http://localhost:8501](http://localhost:8501)**  
2ï¸âƒ£ Type a question (e.g., *"Where is my order?"*)  
3ï¸âƒ£ Click **Send** â€“ the chatbot will respond using **Ollamaâ€™s LLM**  

âœ… **Chatbot is now fully functional with a web interface!** ğŸ‰  

![image](https://github.com/user-attachments/assets/2de713f6-981e-4d0c-ac4e-c0cd8e998321)


---

## **ğŸ“Œ GitHub Commit for Today**
```bash
git add .
git commit -m "Added Streamlit Web UI & fixed API connectivity"
git push origin main
```
âœ… **Now, your GitHub repo is fully updated with today's work!** ğŸš€  

---

### ğŸ¯ **End of Day 2 â€“ Fully Functional Web UI for Chatbot!**  
Now, users can **interact with the chatbot through a web-based UI**, and everything runs seamlessly inside **Docker!** ğŸš€ğŸ”¥ 

### **ğŸ“Œ Contributors**  
ğŸ‘¤ **Shanoj** â€“ *Creator & Developer*  

ğŸ’¡ **Feel free to contribute, submit issues, and improve the chatbot!** ğŸ‰  

---
